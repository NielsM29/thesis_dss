{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26de518-053b-452f-9c25-c6073e0e2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23212cc8-b26c-4077-912f-b805b3dcfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important variables\n",
    "feature_columns = ['CLOUDINESS', 'HUMIDITY', 'MAX_TEMP', 'MIN_TEMP', 'MEAN_TEMP', 'PRECIPITATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0d7985-0f55-48b3-971c-61e50f795ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create time-series graphs\n",
    "def show_save_graph(dataset, feature, extra, timeframe = '2_years', preprocessing = 'before'):\n",
    "    if timeframe == '2_years':\n",
    "        time_var = 733\n",
    "    elif timeframe == '20_years':\n",
    "        time_var = 7305\n",
    "    elif timeframe == '60_years': \n",
    "        time_var = 21917\n",
    "    else:\n",
    "        print('No correct timeframe given in')\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize = (10,3))\n",
    "    plt.plot(dataset['DATE'][0:time_var], dataset[feature][0:time_var])\n",
    "    plt.title(f'{feature} timeseries')\n",
    "    plt.xlabel('Date')\n",
    "    \n",
    "    if preprocessing == 'before':\n",
    "        if feature == 'CLOUDINESS':\n",
    "            plt.ylabel('Cloud cover in oktas')\n",
    "        elif feature == 'HUMIDITY':\n",
    "            plt.ylabel('Humidity in %')\n",
    "        elif feature == 'MAX_TEMP':\n",
    "            plt.ylabel('Maxiumum temperature in 0.1 °C')\n",
    "        elif feature == 'MIN_TEMP':\n",
    "            plt.ylabel('Minimum temperature in 0.1 °C')\n",
    "        elif feature == 'MEAN_TEMP':\n",
    "            plt.ylabel('Mean temperature in 0.1 °C')\n",
    "        elif feature == 'PRECIPITATION':\n",
    "            plt.ylabel('Precipitation in 0.1 mm')\n",
    "        else:\n",
    "            print('No correct feature given in')\n",
    "            return\n",
    "        \n",
    "    elif preprocessing == 'after':\n",
    "        if feature == 'CLOUDINESS':\n",
    "            plt.ylabel('Normalized cloud cover')\n",
    "        elif feature == 'HUMIDITY':\n",
    "            plt.ylabel('Normalized humidity')\n",
    "        elif feature == 'MAX_TEMP':\n",
    "            plt.ylabel('Normalized maxiumum temperature')\n",
    "        elif feature == 'MIN_TEMP':\n",
    "            plt.ylabel('Normalized minimum temperature')\n",
    "        elif feature == 'MEAN_TEMP':\n",
    "            plt.ylabel('Normalized mean temperature')\n",
    "        elif feature == 'PRECIPITATION':\n",
    "            plt.ylabel('Normalized precipitation')\n",
    "        else:\n",
    "            print('No correct feature given in')\n",
    "            return\n",
    "    else:\n",
    "        print('Not indicated if before or after preprocessing')\n",
    "        \n",
    "        \n",
    "    plt.grid(True, linestyle = 'dotted')\n",
    "    plt.savefig(f'graphs/{extra}_{feature}_timeseries_{timeframe}_{preprocessing}.jpg', bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61520a51-a9e2-4c45-8a48-7bb4bb2a6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating necesary folders\n",
    "if 'graphs' not in os.listdir():\n",
    "    os.mkdir('graphs')\n",
    "if 'dataset' not in os.listdir():\n",
    "    os.mkdir('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cfab6d3-957a-4a4b-a13f-75c8de83c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in txt files\n",
    "cloudiness = pd.read_csv('cloudiness.txt', skiprows = 17, header = 1)\n",
    "humidity = pd.read_csv('humidity.txt', skiprows = 17, header = 1)\n",
    "max_temp = pd.read_csv('max_temp.txt', skiprows = 17, header = 1)\n",
    "min_temp = pd.read_csv('min_temp.txt', skiprows = 17, header = 1)\n",
    "mean_temp = pd.read_csv('mean_temp.txt', skiprows = 17, header = 1)\n",
    "precipitation = pd.read_csv('precipitation.txt', skiprows = 17, header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a4239a-acb5-497b-902f-bf15208fd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove first observation, because missing\n",
    "cloudiness = cloudiness[1:]\n",
    "humidity = humidity[1:]\n",
    "max_temp = max_temp[1:]\n",
    "min_temp = min_temp[1:]\n",
    "mean_temp = mean_temp[1:]\n",
    "precipitation = precipitation[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836e2ad1-006a-4782-9f77-c8722c2c77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop irrelevant columns\n",
    "cloudiness = cloudiness.drop([' STAID', ' SOUID', ' Q_CC'], axis = 1)\n",
    "humidity = humidity.drop([' STAID', ' SOUID', ' Q_HU'], axis = 1)\n",
    "max_temp = max_temp.drop([' STAID', ' SOUID', ' Q_TX'], axis = 1)\n",
    "min_temp = min_temp.drop([' STAID', ' SOUID', ' Q_TN'], axis = 1)\n",
    "mean_temp = mean_temp.drop([' STAID', ' SOUID', ' Q_TG'], axis = 1)\n",
    "precipitation = precipitation.drop([' STAID', ' SOUID', ' Q_RR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f65972-3ef0-49f6-a4de-fde2e4515bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns for more clear names\n",
    "cloudiness = cloudiness.rename(columns = {'    DATE':'DATE','   CC':'CLOUDINESS'})\n",
    "humidity = humidity.rename(columns = {'    DATE':'DATE','   HU':'HUMIDITY'})\n",
    "max_temp = max_temp.rename(columns = {'    DATE':'DATE','   TX':'MAX_TEMP'})\n",
    "min_temp = min_temp.rename(columns = {'    DATE':'DATE','   TN':'MIN_TEMP'})\n",
    "mean_temp = mean_temp.rename(columns = {'    DATE':'DATE','   TG':'MEAN_TEMP'})\n",
    "precipitation = precipitation.rename(columns = {'    DATE':'DATE','   RR':'PRECIPITATION'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b958179-5f51-449e-b500-7174a9ffe8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataframes for consistency\n",
    "weather_df = cloudiness.merge(humidity, on = 'DATE', suffixes = ('_z', '_y')).merge(max_temp, on = 'DATE').merge(min_temp, on = 'DATE').merge(mean_temp, on = 'DATE').merge(precipitation, on = 'DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda5751b-618a-449b-b33c-29a4c5fb6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['DATE'] = weather_df['DATE'].astype('str')\n",
    "weather_df['DATE'] = pd.to_datetime(weather_df['DATE'], format = '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f8f4fde-6165-40d5-b9fb-df9b93f70d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset as .csv file\n",
    "weather_df.to_csv('dataset/dutch_weather.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c2a6cab-d914-42e2-a7e6-70afb814e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View graphs of plots before preprocessing\n",
    "time_frames = ['60_years']\n",
    "\n",
    "for time in time_frames:\n",
    "    for feature in feature_columns:\n",
    "        show_save_graph(dataset = weather_df, feature = feature, timeframe = time, preprocessing = 'before', extra = 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214c013d-3bf6-4ceb-98ae-6066912d5f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE              0\n",
      "CLOUDINESS        1\n",
      "HUMIDITY         28\n",
      "MAX_TEMP          0\n",
      "MIN_TEMP          0\n",
      "MEAN_TEMP         0\n",
      "PRECIPITATION     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of missing values per column\n",
    "print(weather_df[0:21924][weather_df == -9999].count(axis = 0))\n",
    "\n",
    "#Use linear interpolation to fill in missing values\n",
    "weather_df= weather_df.replace(-9999, np.NaN)\n",
    "weather_df['HUMIDITY'] = weather_df['HUMIDITY'].interpolate(method='linear')\n",
    "weather_df['CLOUDINESS'] = weather_df['CLOUDINESS'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31bc0dcb-b607-46e0-bbce-28dc18778276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for windowed values\n",
    "cloudiness_weekly = []\n",
    "humidity_weekly = []\n",
    "max_temp_weekly = []\n",
    "min_temp_weekly = []\n",
    "mean_temp_weekly = []\n",
    "precipitation_weekly = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3329cbcc-1f1d-4b52-a4a5-cafec1e909c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window weekly to amplify signal\n",
    "for i in range(0, len(weather_df) - 7 + 1):\n",
    "    cloudiness_weekly.append(weather_df['CLOUDINESS'][i : i + 7].mean())\n",
    "    humidity_weekly.append(weather_df['HUMIDITY'][i : i + 7].mean())\n",
    "    max_temp_weekly.append(weather_df['MAX_TEMP'][i : i + 7].mean())\n",
    "    min_temp_weekly.append(weather_df['MIN_TEMP'][i : i + 7].mean())\n",
    "    mean_temp_weekly.append(weather_df['MEAN_TEMP'][i : i + 7].mean())\n",
    "    precipitation_weekly.append(weather_df['PRECIPITATION'][i : i + 7].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfaec217-cd44-4044-a7e0-97fcc41bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe\n",
    "weather_dict = {'DATE': weather_df['DATE'][6:], 'CLOUDINESS': cloudiness_weekly, 'HUMIDITY': humidity_weekly, 'MAX_TEMP': max_temp_weekly, 'MIN_TEMP': min_temp_weekly, 'MEAN_TEMP': mean_temp_weekly, 'PRECIPITATION': precipitation_weekly,}\n",
    "weather_df_denoised = pd.DataFrame(weather_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89feac75-b3b4-42f3-8c8b-b9bee574957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut dataframe for the amount of time necessary\n",
    "weather_df = weather_df[0:21916]\n",
    "weather_df_denoised = weather_df_denoised[0:21916]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc1adaf3-211b-4209-a4f7-42aae003dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the dataset\n",
    "weather_df_norm = weather_df.copy()\n",
    "weather_df_norm_denoised = weather_df_denoised.copy()\n",
    "\n",
    "for column in feature_columns:\n",
    "    weather_df_norm[column] = (weather_df[column] - weather_df[column].min()) / (weather_df[column].max() - weather_df[column].min())\n",
    "    weather_df_norm_denoised[column] = (weather_df_denoised[column] - weather_df_denoised[column].min()) / (weather_df_denoised[column].max() - weather_df_denoised[column].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad3afac1-2017-40ba-998d-adac9caec0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the graphs of the plots\n",
    "time_frames = ['60_years']\n",
    "\n",
    "for time in time_frames:\n",
    "    for feature in feature_columns:\n",
    "        show_save_graph(dataset = weather_df_norm, feature = feature, timeframe = time, preprocessing = 'after', extra = 'raw')\n",
    "        show_save_graph(dataset = weather_df_norm_denoised, feature = feature, timeframe = time, preprocessing = 'after', extra = 'denoised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eaf7c07-8f77-470f-96e8-dadbb9009608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in feature_columns:\n",
    "    plot_acf(weather_df_norm[column])\n",
    "    plt.title(f'Autocorrelation {column}')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.savefig(f'graphs/autocorrelation_{column}_50timesteps')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b3af13-5f6e-4635-8c56-21a063e5b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in feature_columns:\n",
    "    plot_acf(weather_df_norm_denoised[column])\n",
    "    plt.title(f'Autocorrelation {column}')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.savefig(f'graphs/autocorrelation_{column}_50timesteps')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3b0521-fcf0-4cd9-afa5-9de69996d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset as .csv file\n",
    "weather_df_norm.to_csv('dataset/dutch_weather_norm_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d44809c8-3d15-4a30-8530-db94e94f664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset as .csv file\n",
    "weather_df_norm_denoised.to_csv('dataset/dutch_weather_norm_denoised.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
